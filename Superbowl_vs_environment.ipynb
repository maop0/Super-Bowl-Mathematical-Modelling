{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Below is TOPSIS method\n",
   "id": "300798c722825df4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ],
   "id": "a6b73f92fd68d84f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def topsis(matrix, weights, criteria_types):\n",
    "    \"\"\"\n",
    "    Perform TOPSIS ranking.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : 2D array-like\n",
    "        Decision matrix with shape (m, n) — m alternatives, n criteria.\n",
    "    weights : 1D array-like\n",
    "        Importance weights for each criterion (should sum to 1).\n",
    "    criteria_types : list of str\n",
    "        Each element is 'benefit' or 'cost' indicating the type of criterion.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    scores : ndarray\n",
    "        Closeness coefficient for each alternative (higher = better).\n",
    "    rankings : ndarray\n",
    "        Indices of alternatives ranked from best to worst.\n",
    "    \"\"\"\n",
    "    # Avoid wrong imports\n",
    "    \n",
    "    if sum(weights) != 1:\n",
    "        raise ValueError(\"Weights must sum to 1.\")\n",
    "    if len(weights) != matrix.shape[1]:\n",
    "        raise ValueError(\"Number of weights must match number of criteria.\")\n",
    "    \n",
    "    # Step 1: Normalize the decision matrix\n",
    "    norm_matrix = matrix / np.sqrt((matrix ** 2).sum())\n",
    "    \n",
    "    # Step 2: Multiply by weights\n",
    "    weighted_matrix = norm_matrix * weights\n",
    "\n",
    "    # Step 3: Determine ideal and negative-ideal solutions\n",
    "    ideal_solution = []\n",
    "    negative_ideal_solution = []\n",
    "    for i in range(weighted_matrix.shape[1]):\n",
    "        if criteria_types[i] == '+':\n",
    "            ideal_solution.append(weighted_matrix[:, i].max())\n",
    "            negative_ideal_solution.append(weighted_matrix[:, i].min())\n",
    "        else:\n",
    "            ideal_solution.append(weighted_matrix[:, i].min())\n",
    "            negative_ideal_solution.append(weighted_matrix[:, i].max())\n",
    "    \n",
    "    ideal_solution = np.array(ideal_solution)\n",
    "    negative_ideal_solution = np.array(negative_ideal_solution)\n",
    "\n",
    "    # Step 4: Calculate distances to ideal and negative-ideal solutions\n",
    "    distance_to_ideal = np.sqrt(((weighted_matrix - ideal_solution) ** 2).sum(axis=1))\n",
    "    distance_to_negative_ideal = np.sqrt(((weighted_matrix - negative_ideal_solution) ** 2).sum(axis=1))\n",
    "\n",
    "    # Step 5: Calculate performance score\n",
    "    performance_score = distance_to_negative_ideal / (distance_to_ideal + distance_to_negative_ideal)\n",
    "\n",
    "    return performance_score"
   ],
   "id": "596569c887566eba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from asyncio import log\n",
    "\n",
    "def entropy(infor):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        infor (np.array): input array[1,n]\n",
    "\n",
    "    Returns:\n",
    "        float: entropy value\n",
    "    \"\"\"\n",
    "    if type(infor)!= np.array:\n",
    "        infor = np.array(infor)\n",
    "    return np.sum(-infor * np.log(infor + np.finfo(float).eps)) / np.log(len(infor))\n",
    "\n",
    "\n",
    "# Data Standardization\n",
    "def cost_indicator(matrix):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        matrix (np.array shape (n,n)): decision matrix --> axis = 0 (rows)alternatives, axis = 1 (columns)criteria\n",
    "    Returns:\n",
    "        np.array: cost indicator matrix\n",
    "    \"\"\"\n",
    "    if type(matrix)!= np.array:\n",
    "        matrix = np.array(matrix)\n",
    "    ind = np.argmax(matrix, axis = 1)\n",
    "    maxi = matrix[ind, :]\n",
    "    print(maxi)\n",
    "    print(np.sum(maxi - matrix, axis = 0))\n",
    "    matrix = (maxi - matrix) / np.sum(maxi - matrix, axis = 0)\n",
    "    return matrix\n",
    "\n",
    "def benefit_indicator(matrix):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        matrix (np.array shape (n,n)): decision matrix --> axis = 0 (rows)alternatives, axis = 1 (columns)criteria\n",
    "    Returns:\n",
    "        np.array: benefit indicator matrix\n",
    "    \"\"\"\n",
    "    if type(matrix)!= np.array:\n",
    "        matrix = np.array(matrix)\n",
    "\n",
    "    return matrix / np.sum(matrix, axis = 0)\n",
    "\n",
    "def optimal_value_indicator(matrix, optimal_value):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        matrix (np.array shape (n,n)): decision matrix --> axis = 0 (rows)alternatives, axis = 1 (columns)criteria\n",
    "    Returns:\n",
    "        np.array: benefit indicator matrix\n",
    "    \"\"\"\n",
    "    if type(matrix)!= np.array:\n",
    "        matrix = np.array(matrix)\n",
    "    if optimal_value is None:\n",
    "        optimal_value = np.median(matrix, axis=0)\n",
    "    maxn = np.max(abs(matrix - optimal_value))\n",
    "    if maxn == 0:\n",
    "        maxn = np.finfo(float).eps\n",
    "    matrix = 1 - (abs(matrix - optimal_value) / maxn)\n",
    "    matrix = matrix / np.sum(matrix, axis = 0)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# Calculate Weights\n",
    "def entropy_weights(matrix, indicator, optimal_value = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        matrix (np.array shape (n,n)): decision matrix --> axis = 0 (rows)alternatives, axis = 1 (columns)criteria\n",
    "    Returns:\n",
    "        np.array: entropy weights (1,n)\n",
    "    \"\"\"\n",
    "    if type(matrix)!= np.array:\n",
    "        matrix = np.array(matrix)\n",
    "    # Normalization\n",
    "    #matrix = matrix / matrix.sum(axis=0)\n",
    "    if indicator is optimal_value_indicator:\n",
    "        matrix = indicator(matrix, optimal_value)\n",
    "    else:\n",
    "        matrix = indicator(matrix)\n",
    "    #print(matrix)\n",
    "    matrix = np.where(matrix == 0, np.finfo(float).eps, matrix)\n",
    "    # Entropy calculation\n",
    "    n_criteria = matrix.shape[1]\n",
    "    \n",
    "    entropy_values = np.array(list(map(entropy, matrix.T)))\n",
    "   \n",
    "    #print(entropy_values)\n",
    "    # Degree of diversification\n",
    "    diver = 1 - entropy_values\n",
    "    weights = diver / np.sum(diver)\n",
    "    return weights\n",
    "    \n",
    "\n",
    "entropy_weights(np.array([[10,200,0.5],\n",
    "                          [20,300,0.7],\n",
    "                          [30,250,0.9]]),optimal_value_indicator)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ],
   "id": "591861b912b5beee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def AHP(weights_matrix):\n",
    "    \"\"\"\n",
    "    Perform AHP to derive weights from pairwise comparison matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    weights_matrix : 2D array-like\n",
    "        Pairwise comparison matrix (n x n).\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    weights : ndarray\n",
    "        Derived weights for each criterion.\n",
    "    \"\"\"\n",
    "    if type(weights_matrix)!= np.array:\n",
    "        weights_matrix = np.array(weights_matrix)\n",
    "    eigvals, eigvecs = np.linalg.eig(weights_matrix)\n",
    "    max_index = np.argmax(eigvals)\n",
    "    weights = np.real(eigvecs[:, max_index])\n",
    "    weights = weights / weights.sum()\n",
    "    return weights"
   ],
   "id": "7ae1b39ecf4d73e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "AHP([[1, 3, 5],\n",
    "    [1/3, 1, 2],\n",
    "    [1/5, 1/2, 1]])"
   ],
   "id": "dc7c7caa67270f9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# indicator = [Energy consumption, emission,waste management,water consumption, temperature]\n",
    "#energy_consumption_weights = [renewable energy ratio, energy efficiency, carbon emissions,renewable energy potential]\n",
    "energy_consumption_weights = [[1., 36e6/73208, 343, 2744/365, 7.518]]\n",
    "carbon_emission_of_trans = [[]]\n",
    "waste_management = []\n",
    "#water_usage = [Santa Clara, Atlanta  Georgia,  Inglewood CA ,Glendale,Las Vegas-NV,New Orleans, LA,Seatt,Nashville, Denever] \n",
    "water_usage = [(80+110)*3.78541178/2,149,None,280,830,(300+380)/2,190,(80+110)*3.78541178/2,125]  # gallons per person per day\n",
    "climate = []\n",
    "\n"
   ],
   "id": "933eedce459daf69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_unit(strin,unit):\n",
    "    return strin.replace(unit,\"\")\n",
    "    "
   ],
   "id": "c9b65ce06c854ecd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#import data\n",
    "energy_consumption_data = pd.read_csv('/Users/daniel/Documents/Math_/Superbowl_vs_environment/data/Energy_consmuption.csv')\n",
    "waste_management_data = pd.read_csv('/Users/daniel/Documents/Math_/Superbowl_vs_environment/data/waste_management.csv')\n",
    "climate_data = pd.read_csv('/Users/daniel/Documents/Math_/Superbowl_vs_environment/data/climate.csv')\n",
    "emmision_data = pd.read_csv('/Users/daniel/Documents/Math_/Superbowl_vs_environment/data/transportation.csv')\n",
    "\n"
   ],
   "id": "fcd7c24d792788f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#process energy consumption data\n",
    "\n",
    "for i in energy_consumption_data.columns:\n",
    "    \n",
    "    #removing [int]\n",
    "    energy_consumption_data[i]= pd.DataFrame(map(lambda x:x.split(\"[\")[0], energy_consumption_data[i]))\n",
    "#energy_consumption_data\n",
    "energy_consumption_data['可再生能源占比 (%)'] = pd.DataFrame(map(lambda x:remove_unit(x.split('[')[0],\"%\"), energy_consumption_data['可再生能源占比 (%)']))\n",
    "energy_consumption_data[\"可再生能源占比 (%)\"][0] = energy_consumption_data[\"可再生能源占比 (%)\"][0][1:] \n",
    "energy_consumption_data[\"可再生能源占比 (%)\"][1] = energy_consumption_data[\"可再生能源占比 (%)\"][1][1:] \n",
    "energy_consumption_data['可再生能源占比 (%)'] = pd.DataFrame(map(lambda x:float(x)/100, energy_consumption_data['可再生能源占比 (%)']))\n",
    "energy_consumption_data"
   ],
   "id": "eb5421ee2f22785b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#process emission data\n",
    "emmision_data['公交站数量'] = pd.DataFrame(map(float, emmision_data['公交站数量']))\n",
    "emmision_data['电车/地铁站数量'] = pd.DataFrame(map(float, emmision_data['电车/地铁站数量']))\n",
    "emmision_data\n"
   ],
   "id": "6a2bd6bdc897bd6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#waste management data\n",
    "waste_management_data['总废弃物量'] = pd.DataFrame(map(lambda x: float(remove_unit(x, \"t\")) if type(x) == str else x, waste_management_data['总废弃物量']))\n",
    "waste_management_data['总观众人数'] = pd.DataFrame(map(float, waste_management_data['总观众人数']))\n",
    "waste_management_data['分类回收率'] = pd.DataFrame(map(lambda x: float(remove_unit(x, \"%\"))/100 if type(x) == str else x, waste_management_data['分类回收率']))\n",
    "\n",
    "\n",
    "waste_management_data"
   ],
   "id": "60a903f4001bd3bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**问题1：理解问题 - 环境影响指标体系**\n",
    "**思路**\n",
    "**建立三级指标体系：**\n",
    "\n",
    "\n",
    "- 一级指标：能源、交通、废弃物、水资源、气候适应性\n",
    "\n",
    "\n",
    "- 二级指标：细化的可测量指标 \n",
    "\n",
    "\n",
    "- 三级指标：具体数据采集点 \n",
    "\n",
    "\n",
    "**关键指标** \n",
    "\n",
    "\n",
    "1. **energy consumption**\n",
    "\n",
    "\n",
    "    - 可再生能源比例（%）  \n",
    "\n",
    "\n",
    "    - 场馆能源效率（kWh/座位）   \n",
    "\n",
    "\n",
    "    - 电网清洁度（碳强度 gCO₂/kWh）   \n",
    "\n",
    "\n",
    "    - 当地太阳能/风能潜力   \n",
    "\n",
    "\n",
    "1. **carbon emission by transportation**\n",
    "    - 平均观众出行距离（km）   \n",
    "\n",
    "\n",
    "    - 公共交通覆盖率（%）   \n",
    "\n",
    "\n",
    "    - 机场碳排放效率   \n",
    "\n",
    "\n",
    "    - 电动车充电基础设施密度   \n",
    "\n",
    "\n",
    "1. **waste management**\n",
    "    - 回收率（%）   \n",
    "\n",
    "\n",
    "    - 人均废弃物产生量（kg/人）   \n",
    "\n",
    "\n",
    "    - 堆肥设施可用性   \n",
    "\n",
    "\n",
    "    - 一次性塑料使用政策   \n",
    "\n",
    "\n",
    "1. **water usage**\n",
    "    - 水资源压力指数   \n",
    "\n",
    "\n",
    "    - 雨水回收系统   \n",
    "\n",
    "\n",
    "    - 节水技术应用率   \n",
    "\n",
    "\n",
    "1. **climate**\n",
    "\n",
    "\n",
    "    - 热岛效应强度   "
   ],
   "id": "531398b0b3b0c7ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
